{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Notas para desarrollar clasificador de yemas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links de Referencia:  \n",
    "-  Data preprocessing common tasks:\n",
    "https://becominghuman.ai/image-data-pre-processing-for-neural-networks-498289068258 <br>\n",
    "-  CNN Explained:\n",
    "http://cs231n.github.io/convolutional-networks/ <br>\n",
    "-  Faster RCNN explained https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers utiles:  \n",
    "-  DeepFruits: A Fruit Detection System Using Deep Neural Networks\n",
    "    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5017387/ <br>\n",
    "-  Deep Fruit Detection in Orchards\n",
    "    https://arxiv.org/abs/1610.03677 <br> \n",
    "-  ImageNet Paper https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf (transfer)\n",
    "-  ResNet: Deep Residual Learning for Image Recognition \n",
    "https://arxiv.org/abs/1512.03385\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opciones a probar para el clasificador:\n",
    "-  CNN comun desde 0\n",
    "-  Transfer Learning \n",
    "-  R-CNN (Region Proposal, DeepFruits), no se si es tan necesario porque tenemos patches chicos .\n",
    "-  ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizacion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imageName      0\n",
       "imageOrigin    0\n",
       "xBudCenter     0\n",
       "yBudCenter     0\n",
       "radio          0\n",
       "class          0\n",
       "type           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importamos el csv para analizarlo\n",
    "bud_csv = pd.read_csv('D:\\DHARMa\\Datasets\\BudClassifier\\corpus-26000\\corpus-26000.csv')\n",
    "bud_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imageName      object\n",
       "imageOrigin    object\n",
       "xBudCenter      int64\n",
       "yBudCenter      int64\n",
       "radio           int64\n",
       "class            bool\n",
       "type            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bud_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25278"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bud_csv['class'] == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Uniform Aspect-Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
